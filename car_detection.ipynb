{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sumaiya008/Car-Detection-and-Speed-Calculation-in-Traffic-Videos/blob/main/car_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4hdZFId5bUG2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.feature import hog\n",
        "from skimage import exposure\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCditvWlbV9g",
        "outputId": "5b0c6659-ce0f-4b5a-bc5f-1189f49ad1b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQGMs5ftbZsy",
        "outputId": "a41ee37f-80fb-470a-fb0b-ca13f8781376"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Video created successfully!\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "# Path to the directory containing images\n",
        "image_dir = '/content/drive/MyDrive/CV_Project/Car_data/train/images/'\n",
        "\n",
        "# Output video file path\n",
        "output_video_path = '/content/drive/MyDrive/CV_Project/Car_data/video.avi'\n",
        "\n",
        "# Get the list of image files in the directory\n",
        "image_files = [img for img in os.listdir(image_dir) if img.endswith(('.jpg', '.jpeg', '.png'))]\n",
        "\n",
        "# Sort the image files to maintain order\n",
        "image_files.sort()\n",
        "\n",
        "# Get the dimensions of the first image (assuming all images have the same dimensions)\n",
        "first_image_path = os.path.join(image_dir, image_files[0])\n",
        "first_image = cv2.imread(first_image_path)\n",
        "height, width, _ = first_image.shape\n",
        "\n",
        "# Define the video writer\n",
        "fourcc = cv2.VideoWriter_fourcc(*'XVID')  # You can change the codec as needed\n",
        "fps = 24  # Frames per second\n",
        "video_writer = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
        "\n",
        "# Write each image to the video file\n",
        "for image_file in image_files:\n",
        "    image_path = os.path.join(image_dir, image_file)\n",
        "    frame = cv2.imread(image_path)\n",
        "    video_writer.write(frame)\n",
        "\n",
        "# Release the video writer\n",
        "video_writer.release()\n",
        "\n",
        "print(\"Video created successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Igf13Zlzcjw1"
      },
      "outputs": [],
      "source": [
        "cap = cv2.VideoCapture('/content/drive/MyDrive/CV_Project/Car_data/video.avi')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "a9T8XDKOc1BK"
      },
      "outputs": [],
      "source": [
        "car_cascade = cv2.CascadeClassifier('/content/drive/MyDrive/CV_Project/Car_data/haarcascade_cars.xml')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "y5R5LxGIfDuP",
        "outputId": "d6e93ae3-2de8-4593-cbd2-7ce1a3d83fdb"
      },
      "outputs": [],
      "source": [
        "# cap = cv2.VideoCapture('/content/drive/MyDrive/CV_Project/Car_data/video.avi')\n",
        "# car_cascade = cv2.CascadeClassifier('/content/drive/MyDrive/CV_Project/Car_data/haarcascade_cars.xml')\n",
        "\n",
        "# # Read until the video is completed\n",
        "# while True:\n",
        "#     # Capture frame by frame\n",
        "#     ret, frame = cap.read()\n",
        "\n",
        "#     # Convert the video into grayscale for each frame\n",
        "#     gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "#     # Detect cars in the video\n",
        "#     cars = car_cascade.detectMultiScale(gray, 1.1, 3)\n",
        "\n",
        "#     # To draw a rectangle around each car\n",
        "#     for (x, y, w, h) in cars:\n",
        "#         cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "#         crop_img = frame[y:y+h, x:x+w]\n",
        "\n",
        "#     # Display the frame using cv2_imshow (Google Colab-specific function)\n",
        "#     from google.colab.patches import cv2_imshow\n",
        "#     cv2_imshow(frame)\n",
        "\n",
        "#     # Press 'Q' on the keyboard to exit\n",
        "#     if cv2.waitKey(25) & 0xFF == ord('q'):\n",
        "#         break\n",
        "\n",
        "# # Release the video-capture object\n",
        "# cap.release()\n",
        "# # Close all the frames\n",
        "# cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gFr4Y-cKfNZg"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/var/folders/ph/_s861md14q5c2ykky6q5pgd80000gn/T/ipykernel_11159/3549425564.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrectangle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'video'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mcrop_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "#import libraries of python opencv\n",
        "import cv2\n",
        "\n",
        "# capture video/ video path\n",
        "cap = cv2.VideoCapture('./Car_data/video.avi')\n",
        "\n",
        "\n",
        "#use trained cars XML classifiers\n",
        "car_cascade = cv2.CascadeClassifier('./Car_data/haarcascade_cars.xml')\n",
        "\n",
        "#read until video is completed\n",
        "while cap.isOpened():\n",
        "    \n",
        "    #capture frame by frame\n",
        "    ret, frame = cap.read()\n",
        "    #convert video into gray scale of each frames\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    #detect cars in the video\n",
        "    cars = car_cascade.detectMultiScale(gray, 1.1, 3)\n",
        "    #cv2.im_write(cars)\n",
        "\n",
        "    #to draw a rectangle in each cars \n",
        "    for (x,y,w,h) in cars:\n",
        "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)\n",
        "        cv2.imshow('video', frame)\n",
        "        crop_img = frame[y:y+h,x:x+w]\n",
        "\n",
        "     #press Q on keyboard to exit\n",
        "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "\n",
        "#release the video-capture object\n",
        "cap.release()\n",
        "#close all the frames\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### output video 01 sample code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# importing libraries\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# capturing or reading video\n",
        "cap = cv2.VideoCapture('./Car_data/video.avi')\n",
        "\n",
        "# Get video properties (width, height, and frames per second)\n",
        "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "# Define the codec and create a VideoWriter object\n",
        "fourcc = cv2.VideoWriter_fourcc(*'XVID')  # You can choose other codecs based on your system and preferences\n",
        "out = cv2.VideoWriter('output_video.avi', fourcc, fps, (width, height))\n",
        "\n",
        "# Initial subtractor\n",
        "algo = cv2.createBackgroundSubtractorMOG2()\n",
        "\n",
        "while True:\n",
        "    ret, frame1 = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    grey = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
        "    blur = cv2.GaussianBlur(grey, (3, 3), 5)\n",
        "    \n",
        "    # applying on each frame\n",
        "    img_sub = algo.apply(blur)\n",
        "    dilat = cv2.dilate(img_sub, np.ones((5, 5)))\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
        "    dilatada = cv2.morphologyEx(dilat, cv2.MORPH_CLOSE, kernel)\n",
        "    dilatada = cv2.morphologyEx(dilatada, cv2.MORPH_CLOSE, kernel)\n",
        "    contourSahpe = cv2.findContours(dilatada, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Save the processed frame to the output video\n",
        "    out.write(dilatada)\n",
        "\n",
        "    cv2.imshow(\"OUTPUT\", dilatada)\n",
        "\n",
        "    if cv2.waitKey(1) == 13:\n",
        "        break\n",
        "\n",
        "# Release the VideoWriter and VideoCapture objects\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n",
        "cap.release()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMFq/LCIKMaj0dUGCaE+OmH",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
