{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/sumaiya008/Car-Detection-and-Speed-Calculation-in-Traffic-Videos/blob/main/car_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "4hdZFId5bUG2"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.feature import hog\n",
    "from skimage import exposure\n",
    "# from google.colab.patches import cv2_imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zCditvWlbV9g",
    "outputId": "5b0c6659-ce0f-4b5a-bc5f-1189f49ad1b9"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "\n",
    "# drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jQGMs5ftbZsy",
    "outputId": "a41ee37f-80fb-470a-fb0b-ca13f8781376"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video created successfully!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# Path to the directory containing images\n",
    "# image_dir = '/content/drive/MyDrive/CV_Project/Car_data/train/images/'\n",
    "image_dir = '/Users/analeegraig/Documents/Computer Vision/final_project_data/train/images'\n",
    "\n",
    "# Output video file path\n",
    "# output_video_path = '/content/drive/MyDrive/CV_Project/Car_data/video.avi'\n",
    "output_video_path = '/Users/analeegraig/Documents/Computer Vision/final_project_data/video.avi'\n",
    "\n",
    "# Get the list of image files in the directory\n",
    "image_files = [img for img in os.listdir(image_dir) if img.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "# Sort the image files to maintain order\n",
    "image_files.sort()\n",
    "\n",
    "# Get the dimensions of the first image (assuming all images have the same dimensions)\n",
    "first_image_path = os.path.join(image_dir, image_files[0])\n",
    "first_image = cv2.imread(first_image_path)\n",
    "height, width, _ = first_image.shape\n",
    "\n",
    "# Define the video writer\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')  # You can change the codec as needed\n",
    "fps = 24  # Frames per second\n",
    "video_writer = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "\n",
    "# Write each image to the video file\n",
    "for image_file in image_files:\n",
    "    image_path = os.path.join(image_dir, image_file)\n",
    "    frame = cv2.imread(image_path)\n",
    "    video_writer.write(frame)\n",
    "\n",
    "# Release the video writer\n",
    "video_writer.release()\n",
    "\n",
    "print(\"Video created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Igf13Zlzcjw1"
   },
   "outputs": [],
   "source": [
    "# cap = cv2.VideoCapture('/content/drive/MyDrive/CV_Project/Car_data/video.avi')\n",
    "cap = cv2.VideoCapture(output_video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "a9T8XDKOc1BK"
   },
   "outputs": [],
   "source": [
    "car_cascade = cv2.CascadeClassifier('/Users/analeegraig/Documents/Computer Vision/final_project_data/haarcascade_cars.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "y5R5LxGIfDuP",
    "outputId": "d6e93ae3-2de8-4593-cbd2-7ce1a3d83fdb"
   },
   "outputs": [],
   "source": [
    "# cap = cv2.VideoCapture('/content/drive/MyDrive/CV_Project/Car_data/video.avi')\n",
    "# car_cascade = cv2.CascadeClassifier('/content/drive/MyDrive/CV_Project/Car_data/haarcascade_cars.xml')\n",
    "\n",
    "# # Read until the video is completed\n",
    "# while True:\n",
    "#     # Capture frame by frame\n",
    "#     ret, frame = cap.read()\n",
    "\n",
    "#     # Convert the video into grayscale for each frame\n",
    "#     gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#     # Detect cars in the video\n",
    "#     cars = car_cascade.detectMultiScale(gray, 1.1, 3)\n",
    "\n",
    "#     # To draw a rectangle around each car\n",
    "#     for (x, y, w, h) in cars:\n",
    "#         cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "#         crop_img = frame[y:y+h, x:x+w]\n",
    "\n",
    "#     # Display the frame using cv2_imshow (Google Colab-specific function)\n",
    "#     from google.colab.patches import cv2_imshow\n",
    "#     cv2_imshow(frame)\n",
    "\n",
    "#     # Press 'Q' on the keyboard to exit\n",
    "#     if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "# # Release the video-capture object\n",
    "# cap.release()\n",
    "# # Close all the frames\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "gFr4Y-cKfNZg"
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.1) /Users/runner/work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/w3/x0690xnx12bcnwv0x7n6s4q00000gn/T/ipykernel_1845/3863444665.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m#convert video into gray scale of each frames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m#detect cars in the video\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.8.1) /Users/runner/work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "#import libraries of python opencv\n",
    "import cv2\n",
    "\n",
    "# capture video/ video path\n",
    "cap = cv2.VideoCapture(output_video_path)\n",
    "\n",
    "#use trained cars XML classifiers\n",
    "car_cascade = cv2.CascadeClassifier('/Users/analeegraig/Documents/Computer Vision/final_project_data/haarcascade_cars.xml')\n",
    "\n",
    "#read until video is completed\n",
    "while cap.isOpened():\n",
    "    \n",
    "    #capture frame by frame\n",
    "    ret, frame = cap.read()\n",
    "    #convert video into gray scale of each frames\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    #detect cars in the video\n",
    "    cars = car_cascade.detectMultiScale(gray, 1.1, 3)\n",
    "    #cv2.im_write(cars)\n",
    "\n",
    "    #to draw a rectangle in each cars \n",
    "    for (x,y,w,h) in cars:\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "        cv2.imshow('video', frame)\n",
    "        crop_img = frame[y:y+h,x:x+w]\n",
    "\n",
    "     #press Q on keyboard to exit\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "#release the video-capture object\n",
    "cap.release()\n",
    "#close all the frames\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### output video 01 sample code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# capturing or reading video\n",
    "cap = cv2.VideoCapture(output_video_path)\n",
    "\n",
    "# Get video properties (width, height, and frames per second)\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Define the codec and create a VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')  # You can choose other codecs based on your system and preferences\n",
    "out = cv2.VideoWriter('output_video.avi', fourcc, fps, (width, height))\n",
    "\n",
    "# Initial subtractor\n",
    "algo = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "while True:\n",
    "    ret, frame1 = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    grey = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(grey, (3, 3), 5)\n",
    "    \n",
    "    # applying on each frame\n",
    "    img_sub = algo.apply(blur)\n",
    "    dilat = cv2.dilate(img_sub, np.ones((5, 5)))\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    dilatada = cv2.morphologyEx(dilat, cv2.MORPH_CLOSE, kernel)\n",
    "    dilatada = cv2.morphologyEx(dilatada, cv2.MORPH_CLOSE, kernel)\n",
    "    contourSahpe = cv2.findContours(dilatada, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Save the processed frame to the output video\n",
    "    out.write(dilatada)\n",
    "\n",
    "    cv2.imshow(\"OUTPUT\", dilatada)\n",
    "\n",
    "    if cv2.waitKey(1) == 13:\n",
    "        break\n",
    "\n",
    "# Release the VideoWriter and VideoCapture objects\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMFq/LCIKMaj0dUGCaE+OmH",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
